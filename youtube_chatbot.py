# -*- coding: utf-8 -*-
# """Youtube_chatbot.ipynb

# Automatically generated by Colab.

# Original file is located at
#     https://colab.research.google.com/drive/1N-Y9oLd0WMQMrkqosKBS1QjnXCN8Towg
# """

# pip install youtube_transcript_api
# pip install langchain_community

# pip install faiss-cpu

# pip install -U langchain-huggingface sentence-transformers

from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings, HuggingFaceEndpoint, ChatHuggingFace
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import PromptTemplate
import os
from langchain_core.output_parsers import StrOutputParser
from langchain_core.messages import HumanMessage
from langchain_core.runnables import RunnableParallel, RunnableLambda, RunnablePassthrough
import streamlit as st
from langchain_google_genai import  GoogleGenerativeAI


# UI 





st.title("ðŸŽ¥ YouTube AI Chatbot")

video_url = st.text_input("Enter YouTube video URL (full link)")
user_input = st.chat_input("Ask a question about the video:")



def extract_video_id(url):
    if "v=" in url:
        video_id = url.split("v=")[-1]
        if "&" in video_id:
            video_id = video_id.split("&")[0]
        return video_id
    else:
        return url  # Assume user just gave the ID

 
transcript_text = ""

if video_url:
    video_id = extract_video_id(video_url)

    try:
        api = YouTubeTranscriptApi()
        transcript_list = api.fetch(video_id, languages=['en', 'hi'])
        transcript_text = " ".join(chunk.text for chunk in transcript_list)
        st.success("Transcript fetched successfully!")

    except TranscriptsDisabled:
        st.warning("No captions available for this video.")
    except Exception as e:
        st.error(f"Error fetching transcript: {e}")


documents = []

# Text Splitting

if transcript_text:
    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)
    documents = splitter.create_documents([transcript_text])


# Embedding

embeddings = HuggingFaceEmbeddings(model_name = 'sentence-transformers/all-MiniLM-L6-v2', api_key =st.secrets['HUGGINGFACEHUB_API_TOKEN'])

vector_store = FAISS.from_documents(documents, embeddings)

# vector_store.index_to_docstore_id

# Retrieval

retriever = vector_store.as_retriever(search_type = 'similarity', search_kwargs = {'k':4})


#  Augmentation

prompt = PromptTemplate(
    template = """
    You are a helpful assistant.
      Answer ONLY from the provided transcript context.
      If the context is insufficient, just say you don't know.

      {context}

      Question: {question}
    """,

    input_variables=['context', 'question']
)

parser = StrOutputParser()

# llm = HuggingFaceEndpoint(
#     repo_id = "mistralai/Mistral-7B-Instruct-v0.2",
#     task = "text-generation",
#     huggingfacehub_api_token = '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'
# )

# model = ChatHuggingFace(llm=llm)

model = GoogleGenerativeAI(model = 'gemini-2.5-flash', api_key = st.secrets['GOOGLE_API_KEY '])

# question = 'india vs pakistan'

# retrieved_docs = retriever.invoke(question)


# context = "\n\n".join(doc.page_content for doc in retrieved_docs)

# final_prompt = prompt.invoke({'context': context, 'question': question})



# Generation

# Forming a Chain


def join_doc(retrieved_docs):
  result = '\n\n'.join(doc.page_content for doc in retrieved_docs)
  return result

parallel = RunnableParallel({
    'question': RunnablePassthrough(),
    'context': retriever | RunnableLambda(join_doc)
})



chain = parallel | prompt | model | parser


if user_input:
    if transcript_text:
        answer = chain.invoke(user_input)
        st.chat_message("assistant").write(answer)
    else:
        st.warning("Transcript not available. Cannot answer questions.")



    